---
title: "Biostat 203B Homework 2"
author: "Tomoki Okuno"
subtitle: Due Feb 6 @ 11:59PM
output:
  html_document:
    toc: yes
    toc_depth: 4
  pdf_document:
    toc: yes
    toc_depth: '4'
---

Display machine information for reproducibility:
```{r}
sessionInfo()
```

```{r setup, message=F}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, cache.lazy = FALSE)
library(tidyverse)
library(data.table)
library(lubridate)
```

```{r}
os <- sessionInfo()$running
if (str_detect(os, "Linux")) {
  mimic_path <- "/mnt/mimiciv/1.0"
} else if (str_detect(os, "macOS")) {
  mimic_path <- "/Users/tomokiokuno/mimic-iv-1.0"
}
```

In this exercise, we use tidyverse (ggpot2, dplyr, etc) to explore the [MIMIC-IV](https://mimic.mit.edu/docs/iv/) data introduced in [homework 1](https://ucla-biostat-203b.github.io/2022winter/hw/hw1/hw1.html) and to build a cohort of ICU stays.

```{r}
# tree -s -L 2 /Users/huazhou/Documents/Box\ Sync/MIMIC/mimic-iv-1.0
system(str_c("tree -s -L 2 ", shQuote(mimic_path)), intern = TRUE)
```

## Q1. `read.csv` (base R) vs `read_csv` (tidyverse) vs `fread` (data.table)

There are quite a few utilities in R for reading plain text data files. Let us test the speed of reading a moderate sized compressed csv file, `admissions.csv.gz`, by three programs: `read.csv` in base R, `read_csv` in tidyverse, and `fread` in the popular data.table package. 

Which function is fastest? Is there difference in the (default) parsed data types? (Hint: R function `system.time` measures run times.)

For later questions, we stick to the tidyverse.

**Solution:** I used `system.time` to measure run times for the three functions. Looking at user time, CPU time charged for the execution of user instructions, `fread` was the fastest function.
```{r}
system.time(tmp_r <- read.csv(str_c(mimic_path,"/core/admissions.csv.gz")))
system.time(tmp_t <- read_csv(str_c(mimic_path,"/core/admissions.csv.gz")))
system.time(tmp_f <- fread(str_c(mimic_path,"/core/admissions.csv.gz")))
```

**Solution:** Next, I used `str` to confirm data types for the three functions. Obviously, there are differences between them. For instance, both `read.csv` and `fread` read `subject_id` as `integer` while `read_csv` read this as `double (numeric)`. Also, both `read_csv` and `fread` imported the time as `POSIXct`, but `read.csv` imported as `charactor`.
```{r}
str(tmp_r)
str(tmp_t)
str(tmp_f)
```


## Q2. ICU stays

`icustays.csv.gz` (<https://mimic.mit.edu/docs/iv/modules/icu/icustays/>) contains data about Intensive Care Units (ICU) stays. The first 10 lines are
```{r}
system(
  str_c(
    "zcat < ", 
    shQuote(str_c(mimic_path, "/icu/icustays.csv.gz")), 
    " | head"
  ), 
  intern = TRUE
)
```

1. Import `icustatys.csv.gz` as a tibble `icustays_tble`.

**Solution:** I used `read_csv` to import this file as a tibble and sorted it by `subject_id` and `hadm_id`.
```{r}
# imported as a master file for work efficiency
icustays_master <- read_csv(str_c(mimic_path, "/icu/icustays.csv.gz"))
icustays_tble <- icustays_master %>%
  arrange(subject_id, hadm_id) %>%
  print(width = Inf)
```

2. How many unique `subject_id`? Can a `subject_id` have multiple ICU stays?

**Solution:** Aggregation of `icustays_tble` by `subject_id` yielded 53,150 unique `subject_id`'s, which is less than the total number of rows (76,540). Thus, `subject_id` can have multiple ICU stays.
```{r}
nrow(distinct(icustays_tble, subject_id))
```

3. For each `subject_id`, let's only keep the first ICU stay in the tibble `icustays_tble`.

**Solution:** I used `arrange` to sort `intime` in ascending order, and then removed the duplicates `subject_id`. This method should be faster than using `filter` and `min`. As a result, the new table has 53,150 rows.
```{r}
icustays_tble <- icustays_tble %>%
  arrange(subject_id, intime) %>%
  distinct(subject_id, .keep_all = TRUE) %>%
  print(width = Inf)
```

## Q3. `admission` data

Information of the patients admitted into hospital is available in `admissions.csv.gz`. See <https://mimic.mit.edu/docs/iv/modules/core/admissions/> for details of each field in this file. The first 10 lines are
```{r}
system(
  str_c(
    "zcat < ", 
    shQuote(str_c(mimic_path, "/core/admissions.csv.gz")), 
    " | head"
  ), 
  intern = TRUE
)
```

1. Import `admissions.csv.gz` as a tibble `admissions_tble`.

**Solution:** I used `read_csv` to import this file as a tibble and obtained a 523,740 Ã— 15 table.
```{r}
admissions_master <- read_csv(str_c(mimic_path,"/core/admissions.csv.gz"))
admissions_tble <- admissions_master %>%
  print(width = Inf)
```

2. Let's only keep the admissions that have a match in `icustays_tble` according to `subject_id` and `hadm_id`.

**Solution:** I used `semi_join` to keep only the rows of `admissions_tble` with the same `subject_id` and `hadm_id` as `icustays_tble`.
```{r}
admissions_tble <- admissions_tble %>%
  arrange(subject_id, hadm_id) %>%
  semi_join(icustays_tble, by = c("subject_id", "hadm_id")) %>%
  print(width = Inf)
```

3. Summarize the following variables by graphics.

**Solution:** I chose bar plots to show the distributions:

- admission year
```{r}
ggplot(data = admissions_tble) + 
  geom_bar(mapping = aes(x = year(admittime))) +
  labs(title = "Distribution of admission time by year") +
  labs(x = "Admission year")
```

- admission month
```{r}
ggplot(data = admissions_tble) + 
  stat_count(mapping = aes(x = lubridate::month(admittime, label = T))) +
  labs(title = "Distribution of admission time by month") +
  labs(x = "Admission month")
```

- admission month day
```{r}
ggplot(data = admissions_tble) + 
  stat_count(mapping = aes(x = mday(admittime))) +
  labs(title = "Distribution of admission time by month and day") +
  labs(x = "Admission month day")
```

- admission week day  
```{r}
ggplot(data = admissions_tble) + 
  stat_count(mapping = aes(x = lubridate::wday(admittime, label = T))) +
  labs(title = "Distribution of admission time by week day") +
  labs(x = "Admission week day")
```

- admission hour (anything unusual?)
```{r}
ggplot(data = admissions_tble) + 
  stat_count(mapping = aes(x = hour(admittime))) +
  labs(title = "Distribution of admission time by hour") +
  labs(x = "Admission hour")
```

**Solution:** From the above graph, 0 AM and 7 AM appear to be unusual since the frequencies are higher than other times despite a late night and an early morning. That may be caused by some operation of the hospital.


## Q4. `patients` data

Patient information is available in `patients.csv.gz`. See <https://mimic.mit.edu/docs/iv/modules/core/patients/> for details of each field in this file. The first 10 lines are
```{r}
system(
  str_c(
    "zcat < ", 
    shQuote(str_c(mimic_path, "/core/patients.csv.gz")), 
    " | head"
  ), 
  intern = TRUE
)
```

1. Import `patients.csv.gz` (<https://mimic.mit.edu/docs/iv/modules/core/patients/>) as a tibble `patients_tble` and only keep the patients who have a match in `icustays_tble` (according to `subject_id`).

**Solution:** I used `read_csv` to import this file as a tibble. The subset contains 53,150 rows.
```{r}
patients_master <- read_csv(str_c(mimic_path,"/core/patients.csv.gz"),
                            show_col_types = FALSE)
patients_tble <- patients_master %>%
  arrange(subject_id) %>%
  semi_join(icustays_tble, by = c("subject_id")) %>%
  print(width = Inf)
```

2. Summarize variables `gender` and `anchor_age`, and explain any patterns you see.

**Solution:** I used a box plot and a bar plot to visualize the distribution of the two variables.

For the box plot:

- Both distributions are negatively skewed and have almost the same range;
- The 25th, 50th (median), and 75th percentile ages of women are higher than those of men.  

For the bar plot:

- Many ages have more males than females;
- There is a significant number of patients with the maximum age (91 years).
```{r}
p1 <- ggplot(data = patients_tble, mapping = aes(x = gender, y = anchor_age)) + 
  stat_boxplot(geom = "errorbar", width = 0.2) + 
  geom_boxplot() +
  labs(title = "Distributions for anchor age by gender") +
  labs(x = "Gender", y = "Anchor age (years)")
p2 <- ggplot(data = patients_tble) + 
  geom_bar(mapping = aes(x = anchor_age, fill = gender)) +
  labs(title = "") +
  labs(x = "Anchor age (years)", fill = "Gender")
max(patients_tble$anchor_age)
gridExtra::grid.arrange(p1, p2, nrow = 1)
```

## Q5. Lab results

`labevents.csv.gz` (<https://mimic.mit.edu/docs/iv/modules/hosp/labevents/>) contains all laboratory measurements for patients. The first 10 lines are
```{r}
system(
  str_c(
    "zcat < ", 
    shQuote(str_c(mimic_path, "/hosp/labevents.csv.gz")), 
    " | head"
  ), 
  intern = TRUE
)
```
```{r}
system(
  str_c(
    "zcat < ", 
    shQuote(str_c(mimic_path, "/hosp/d_labitems.csv.gz")), 
    " | head"
  ), 
  intern = TRUE
)
```

1. Find how many rows are in `labevents.csv.gz`.

**Solution:** There are 122,103,667 rows in `labevents.csv.gz`.
```{r}
system(
  str_c(
    "zcat < ", 
    shQuote(str_c(mimic_path, "/hosp/labevents.csv.gz")),
    " | tail -n +2 | wc -l"
  ), 
  intern = TRUE
)
```

2. We are interested in the lab measurements of creatinine (50912), potassium (50971), sodium (50983), chloride (50902), bicarbonate (50882), hematocrit (51221), white blood cell count (51301), glucose (50931), magnesium (50960), and calcium (50893). Retrieve a subset of `labevents.csv.gz` only containing these items for the patients in `icustays_tble` as a tibble `labevents_tble`.  

Hint: `labevents.csv.gz` is a data file too big to be read in by the `read_csv` function in its default setting. Utilize the `col_select` and `lazy` options in the `read_csv` function to reduce the memory burden.

**Solution:** I imported this and used `left_join` to add `label` in `d_labitems.csv.gz` as a new variable. The subset has 16,698,462 rows.
```{r}
labevents_master <- 
  read_csv(str_c(mimic_path,"/hosp/labevents_filtered_itemid.csv.gz"), 
           col_types = cols_only(subject_id = col_double(), 
                                 itemid = col_double(), 
                                 charttime = col_datetime(), 
                                 valuenum = col_double()),
           lazy = TRUE)
d_labitems_tble <- read_csv(str_c(mimic_path,"/hosp/d_labitems.csv.gz"))
# item list we plan to use (but we do not need this anymore)
choice_lab <- c("50912", "50971", "50983", "50902", "50882", 
                "51221", "51301", "50931", "50960", "50893")
labevents_tble <- labevents_master
labevents_tble <- labevents_tble %>%
  arrange(subject_id, itemid) %>%
  # only contain these items for the patients in icustays_tble
  semi_join(icustays_tble, by = c("subject_id")) %>%
  # add label in d_labitems
  left_join(select(d_labitems_tble, itemid, label), by = c("itemid")) %>%
  print(width = Inf)
```

3. Further restrict `labevents_tble` to the first lab measurement during the ICU stay.

**Solution:** The following code made `labevents_tble` 51,623 rows. I used `select` to keep `subject_id` and ten lab measurements, or only 11 columns.
```{r}
if (file.exists("labevents_tble.rds")) {
  labevents_tble <- read_rds("labevents_tble.rds")
} else {
  labevents_tble <- labevents_tble %>%
<<<<<<< HEAD
    # add intime from icustays_tble to find the first lab measurement
    left_join(select(icustays_tble, subject_id, intime, outtime), 
              by = c("subject_id")) %>%
    # keep only lab measurements after intime
=======
    # add intime and outtime from icustays_tble to find the first lab measurement
    left_join(select(icustays_tble, subject_id, intime, outtime), 
              by = c("subject_id")) %>%
    # keep only lab measurements between intime and outtime
>>>>>>> develop
    filter(charttime >= intime, charttime <= outtime) %>%
    # sort charttime in ascending order by subject_id and item_id
    group_by(subject_id, itemid) %>%
    arrange(charttime, .by_group = TRUE) %>%
    # keep only the first lab measurement by group
    slice_head(n = 1) %>%
    # keep only 11 columns and spread label and valuenum
    ungroup() %>%
    select(-c(itemid, charttime, intime, outtime)) %>%
    pivot_wider(names_from = label, values_from = valuenum) %>%
    # avoid space in column name
    rename(Calcium = "Calcium, Total", WBC = "White Blood Cells") %>%
    print(width = Inf) %>%
    write_rds("labevents_tble.rds")
}
```

4. Summarize the lab measurements by appropriate numerics and graphics.

**Solution:** For numeric, I used `summary` to output summary statistics, implying that some appear to have missing ant extreme values. Taking this into account, for graphics, I removed values below the 2.5th and above the 97.5th percentile and then displayed these distributions in the following box plots. The distributions for Creatinine, Glucose, and White Blood Cells (WBC) are far from normal distribution, unlike the others.
```{r}
# numerical summary
summary(labevents_tble[-1])
# graphical summary
labevents_tble %>%
  select(2:11) %>%
  gather() %>%
  group_by(key) %>%
  filter(value > quantile(value, 0.025, na.rm = TRUE) 
         & value < quantile(value, 0.975, na.rm = TRUE)) %>%
  ungroup %>%
  ggplot() +
  geom_boxplot(mapping = aes(y = value)) +
  facet_wrap(~key, scales = "free_y") +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) 
```

## Q6. Vitals from charted events

`chartevents.csv.gz` (<https://mimic.mit.edu/docs/iv/modules/icu/chartevents/>) contains all the charted data available for a patient. During their ICU stay, the primary repository of a patientâ€™s information is their electronic chart. The `itemid` variable indicates a single measurement type in the database. The `value` variable is the value measured for `itemid`. The first 10 lines of `chartevents.csv.gz` are
```{r}
system(
  str_c(
    "zcat < ", 
    shQuote(str_c(mimic_path, "/icu/chartevents.csv.gz")), 
    " | head"), 
  intern = TRUE
)
```
`d_items.csv.gz` (<https://mimic.mit.edu/docs/iv/modules/icu/d_items/>) is the dictionary for the `itemid` in `chartevents.csv.gz`. 
```{r}
system(
  str_c(
    "zcat < ", 
    shQuote(str_c(mimic_path, "/icu/d_items.csv.gz")), 
    " | head"), 
  intern = TRUE
)
```

1. We are interested in the vitals for ICU patients: heart rate (220045), mean non-invasive blood pressure (220181), systolic non-invasive blood pressure (220179), body temperature in Fahrenheit (223761), and respiratory rate (220210). Retrieve a subset of `chartevents.csv.gz` only containing these items for the patients in `icustays_tble` as a tibble `chartevents_tble`.

**Solution:** Importing this and adding `label` in `d_items.csv.gz` as a new column created a tibble with 23,679,058 Ã— 6. The subset retained all the rows of the original.
```{r}
chartevents_master <-
  read_csv(str_c(mimic_path,"/icu/chartevents_filtered_itemid.csv.gz"),
           col_types = cols_only(subject_id = col_double(),
                                 hadm_id = col_double(),
                                 itemid = col_double(),
                                 itemid = col_double(), 
                                 charttime = col_datetime(), 
                                 valuenum = col_double()),
           lazy = TRUE)
d_items_tble <- read_csv(str_c(mimic_path,"/icu/d_items.csv.gz"))
# item list we plan to use (but we do not need this anymore)
choice2 <- c("220045", "220181", "220179", "223761", "220210")
chartevents_tble <- chartevents_master
chartevents_tble <- chartevents_tble %>%
  # only containing these items for the patients in icustays_tble
  semi_join(icustays_tble, by = c("subject_id")) %>%
  # add label in d_items
  left_join(select(d_items_tble, itemid, label), by = c("itemid")) %>%
  print(width = Inf)
```

2. Further restrict `chartevents_tble` to the first vital measurement during the ICU stay.

**Solution:** I ran almost the same code as Q5-3 and obtained a tibble with 53,136 Ã— 6, which consists of only `subject_id` and five vital measurements.
```{r}
# file.remove("chartevents_tble.rds")
if (file.exists("chartevents_tble.rds")) {
  chartevents_tble <- read_rds("chartevents_tble.rds")
} else {
  chartevents_tble <- chartevents_tble %>%
<<<<<<< HEAD
    # add intime from icustays_tble to find the first vital measurement
    left_join(select(icustays_tble, subject_id, intime, outtime), 
              by = c("subject_id")) %>%
    # keep only vital measurements after intime
=======
    # add intime and outtime from icustays_tble to find the first vital measurement
    left_join(select(icustays_tble, subject_id, intime, outtime), 
              by = c("subject_id")) %>%
    # keep only vital measurements between intime and outtime
>>>>>>> develop
    filter(charttime >= intime, charttime <= outtime) %>%
    # sort charttime in ascending order by subject_id and item_id
    group_by(subject_id, itemid) %>%
    arrange(charttime, .by_group = TRUE) %>%
    # keep only the first vital measurement by group
    slice_head(n = 1) %>%
    # restrict columns and spread label and valuenum
    ungroup() %>%
    select(c(subject_id, label, valuenum)) %>%
    pivot_wider(names_from = label, values_from = valuenum) %>%
    # avoid space in column name
    rename(HR = "Heart Rate", RR = "Respiratory Rate", 
           Mean_BP = "Non Invasive Blood Pressure systolic",
           Systolic_BP = "Non Invasive Blood Pressure mean",
           BT = "Temperature Fahrenheit") %>%
    print(width = Inf) %>%
    write_rds("chartevents_tble.rds")
}
```

3. Summarize these vital measurements by appropriate numerics and graphics.

**Solution:** As with Q5-4, I output summary statistics, which indicates some extreme values exist. Then I used box plots that omitted values outside from the 2.5th to 97.5th percentile to make the distributions more visible. All distributions seem to be approximately close to normal.
```{r}
# numerical summary
summary(chartevents_tble[-1])
# graphical summary
chartevents_tble %>%
  select(2:6) %>%
  gather() %>%
  group_by(key) %>%
  filter(value > quantile(value, 0.025, na.rm = TRUE) 
         & value < quantile(value, 0.975, na.rm = TRUE)) %>%
  ungroup %>%
  ggplot() +
  geom_boxplot(mapping = aes(y = value)) +
  facet_wrap(~key, scales = "free_y") +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank())
```

## Q7. Putting things together

Let us create a tibble `mimic_icu_cohort` for all ICU stays, where rows are  

- first ICU stay of each unique adult (age at admission > 18)

and columns contain at least following variables  

- all variables in `icustays.csv.gz`  
- all variables in `admission.csv.gz`  
- all variables in `patients.csv.gz`  
- first lab measurements during ICU stay  
- first vital measurements during ICU stay
- an indicator variable `thirty_day_mort` whether the patient died within 30 days of hospital admission (30 day mortality)

**Solution:** Here is the code to create `mimic_icu_cohort` with 53,065 rows and 43 columns. I set `thirty_day_mort` as `TRUE` if a person died within 30 days; `FALSE` otherwise. I thought first that patients who haven't died were in another category, though.
```{r}
# file.remove("mimic_icu_cohort.rds")
if (file.exists("mimic_icu_cohort.rds")) {
  mimic_icu_cohort <- read_rds("mimic_icu_cohort.rds")
} else {
  mimic_icu_cohort <- icustays_tble %>%
    left_join(admissions_tble, by = c("subject_id", "hadm_id")) %>%
    left_join(patients_tble, by = c("subject_id")) %>%
    left_join(labevents_tble, by = c("subject_id")) %>%
    left_join(chartevents_tble, by = c("subject_id")) %>%
    # compute age at admission
    mutate(age_hadm = anchor_age + year(admittime) - anchor_year) %>%
    # keep only patients aged over 18 at admission
    filter(age_hadm > 18) %>%
    # create thirty_day_mort with T if a patient died <= 30 days and F if not
    mutate(thirty_day_mort = 
             ifelse(is.na(deathtime), "FALSE", 
                    ifelse(as.Date(deathtime) - as.Date(admittime) <= 30, 
                           "TRUE", "FALSE"))) %>%
    print(width = Inf) %>%
    write_rds("mimic_icu_cohort.rds")
}
table(mimic_icu_cohort$thirty_day_mort)
```

## Q8. Exploratory data analysis (EDA)

Summarize following information using appropriate numerics or graphs.

- `thirty_day_mort` vs demographic variables (ethnicity, language, insurance, marital_status, gender, age at hospital admission)

**Solution:** I used bar plots for categorical variables (ethnicity, language, insurance, marital_status and gender) and a box plot for a numerical variable (age at hospital admission).

- `thirty_day_mort` vs ethnicity

**Brief comment:** The percentage of white patients who died within 30 days is lower than that of those who did not, while the proportion of the unknown has the opposite relationship. 
```{r}
# numerical information
round(prop.table(table(mimic_icu_cohort$ethnicity, 
                       mimic_icu_cohort$thirty_day_mort) ,2), 2)
# graphical information
mimic_icu_cohort %>%
  ggplot() +
  geom_bar(mapping = aes(x = thirty_day_mort, fill = ethnicity), 
           position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "30 day mortality", y = "percent") +
  scale_x_discrete(limits = ) +
  labs(title = "30 day mortality vs ethnicity") 
```

- `thirty_day_mort` vs language, insurance, marital_status, and gender

**Brief comment:**

- For language, no different trends observe between the two categories: About 90% of the patients speak English.
- For insurance, patients who died within 30 days are more likely to have medicare than those who did not, rather than other insurances.
- For marital status (excluding `NA`), the adult patients who died within 30 days have a smaller proportion of the single than those who did not die, but a larger proportion of the widowed.
- For gender, there is little difference in the ratio of men to women between them.
```{r}
# numerical information
round(prop.table(table(mimic_icu_cohort$language, 
                       mimic_icu_cohort$thirty_day_mort) ,2), 2)
round(prop.table(table(mimic_icu_cohort$insurance, 
                       mimic_icu_cohort$thirty_day_mort) ,2), 2)
round(prop.table(table(mimic_icu_cohort$marital_status, 
                       mimic_icu_cohort$thirty_day_mort) ,2), 2)
round(prop.table(table(mimic_icu_cohort$gender, 
                       mimic_icu_cohort$thirty_day_mort) ,2), 2)
# graphical information
q1 <- mimic_icu_cohort %>%
  ggplot() +
  geom_bar(mapping = aes(x = thirty_day_mort, fill = language), 
           position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "30 day mortality", y = "percent") +
  labs(title = "30 day mortality vs language") 
q2 <- mimic_icu_cohort %>%
  ggplot() +
  geom_bar(mapping = aes(x = thirty_day_mort, fill = insurance), 
           position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "30 day mortality", y = "percent") +
  labs(title = "30 day mortality vs insurance") 
q3 <- subset(mimic_icu_cohort, !is.na(marital_status)) %>%
  ggplot() +
  geom_bar(mapping = aes(x = thirty_day_mort, fill = marital_status), 
           position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "30 day mortality", y = "percent") +
  labs(title = "30 day mortality vs marital status") 
q4 <- mimic_icu_cohort %>%
  ggplot() +
  geom_bar(mapping = aes(x = thirty_day_mort, fill = gender), 
           position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "30 day mortality", y = "percent") +
  labs(title = "30 day mortality vs gender")
gridExtra::grid.arrange(q1, q2, q3, q4, nrow = 2)
```

- `thirty_day_mort` vs age at hospital admission

**Brief comment:** Patients aged over 18 who died within 30 days tend to be older than those who did not.
```{r}
# numerical information
tapply(mimic_icu_cohort$age_hadm, mimic_icu_cohort$thirty_day_mort, summary)
# graphical information
ggplot(data = mimic_icu_cohort) + 
  geom_boxplot(aes(x = thirty_day_mort, y = age_hadm)) +
  labs(title = "30 day mortality vs age at hospital admission") +
  labs(x = "30 day mortality") +
  labs(y = "Age at hospital admission") 
```

- `thirty_day_mort` vs first lab measurements

**Solution:** I used a similar method with Q5-4 except for grouping by `thirty_day_mort` as follows.
```{r}
# numerical summary
mimic_icu_cohort %>%
  select(c(27:36, 43)) %>%
  gather(key = key, value = value, -thirty_day_mort) %>%
  filter(!is.na(value)) %>%
  filter(value > quantile(value, 0.025, na.rm = TRUE) 
         & value < quantile(value, 0.975, na.rm = TRUE)) %>%
  group_by(key, thirty_day_mort) %>%
  summarize(Mean   =     mean(value,       na.rm = TRUE), 
            Median =   median(value,       na.rm = TRUE), 
            SD     =       sd(value,       na.rm = TRUE), 
            Min    =      min(value,       na.rm = TRUE), 
            Max    =      max(value,       na.rm = TRUE), 
            Q1     = quantile(value, 0.25, na.rm = TRUE), 
            Q3     = quantile(value, 0.75, na.rm = TRUE))  
# graphical summary
mimic_icu_cohort %>%
  gather(27:36, key = "key", value = "value") %>%
  group_by(key) %>%
  filter(value > quantile(value, 0.025, na.rm = TRUE) 
         & value < quantile(value, 0.975, na.rm = TRUE)) %>%
  ungroup %>%
  ggplot(mapping = aes(x = thirty_day_mort, y = value)) +
  geom_boxplot() +
  labs(x = "30 day mortality") +
  facet_wrap(~key, scales = "free_y") +
  labs(title = "Distributions for first lab measurements by 30 day mortality")
```

**Brief comment:** For Bicarbonate and Creatinine, there appear to be big differences between the two categories because one of the medians is closer to the edge of the other box. Also, it may be worth testing whether there are statistically significant differences for glucose and white blood cells as well.

- `thirty_day_mort` vs first vital measurements

**Solution:** I used a similar method with Q6-3 except for grouping by `thirty_day_mort`.
```{r}
# numerical summary
mimic_icu_cohort %>%
  select(c(37:41, 43)) %>%
  gather(key = key, value = value, -thirty_day_mort) %>%
  filter(!is.na(value)) %>%
  filter(value > quantile(value, 0.025, na.rm = TRUE) 
         & value < quantile(value, 0.975, na.rm = TRUE)) %>%
  group_by(key, thirty_day_mort) %>%
  summarize(Mean   =     mean(value,       na.rm = TRUE), 
            Median =   median(value,       na.rm = TRUE), 
            SD     =       sd(value,       na.rm = TRUE), 
            Min    =      min(value,       na.rm = TRUE), 
            Max    =      max(value,       na.rm = TRUE), 
            Q1     = quantile(value, 0.25, na.rm = TRUE), 
            Q3     = quantile(value, 0.75, na.rm = TRUE))  
# graphical summary
mimic_icu_cohort %>%
  gather(37:41, key = "key", value = "value") %>%
  group_by(key) %>%
  filter(value > quantile(value, 0.025, na.rm = TRUE) 
         & value < quantile(value, 0.975, na.rm = TRUE)) %>%
  ungroup %>%
  ggplot(mapping = aes(x = thirty_day_mort, y = value)) +
  geom_boxplot() +
  labs(x = "30 day mortality") +
  facet_wrap(~key, scales = "free_y") +
  labs(title = 
         "Distributions for first vital measurements by 30 day mortality")
```

**Brief comment:** The values for Heart Rate (HR) and Respiratory Rate (RR) tend to be relatively higher for patients who died within 30 days than those who did not. For the rest, no major differences can be seen.

- `thirty_day_mort` vs first ICU unit

**Solution:** I summarized this in a similar way to `thirty_day_mort` vs demographic variables.
```{r}
# numerical summary
round(prop.table(table(mimic_icu_cohort$first_careunit, 
                       mimic_icu_cohort$thirty_day_mort) ,2), 2)
# graphical summary
mimic_icu_cohort %>%
  ggplot() +
  geom_bar(mapping = aes(x = thirty_day_mort, fill = first_careunit), 
           position = "fill") +
  labs(y = "percent") +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Proportion for the first ICU unit by 30 day mortality") +
  labs(x = "30 day mortality", fill = "First ICU unit")
```

**Brief comment:** The proportion of CVICU for patients who died within 30 days is 14 points lower than that of those who did not. On the other hand, for MICU, the proportion of patients who died within 30 days is 9 points higher. Other than that, there appears to be little difference.